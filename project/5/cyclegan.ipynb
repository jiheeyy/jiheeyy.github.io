{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMKFHB5UMO9_"
      },
      "source": [
        "## Imports, GPU"
      ],
      "id": "nMKFHB5UMO9_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f9385ef-2ca2-4ce5-b3ac-fbe408f41228"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from random import randrange\n"
      ],
      "id": "7f9385ef-2ca2-4ce5-b3ac-fbe408f41228"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2b0e966-68da-400e-b1a9-46fa321cf074"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Enable CUDA if the GPU is available\n",
        "\"\"\"\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "id": "d2b0e966-68da-400e-b1a9-46fa321cf074"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulrrTdWdGfky"
      },
      "source": [
        "## Config"
      ],
      "id": "ulrrTdWdGfky"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Bfbt-m4GgxT"
      },
      "outputs": [],
      "source": [
        "DRIVE_PREFIX = './drive/MyDrive/UChicago/Computer Vision/Vision Final'\n",
        "TRAIN_DIR = DRIVE_PREFIX + \"/train\"\n",
        "VAL_DIR = DRIVE_PREFIX + \"/val\"\n",
        "RUN_NUM = 0\n",
        "BATCH_SIZE = 1 # Changing this to 100 used up all GPU memory\n",
        "LEARNING_RATE = 1e-5\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_WORKERS = 2\n",
        "NUM_EPOCHS = 150\n",
        "LOAD_MODEL = True\n",
        "SAVE_MODEL = False\n",
        "CHECKPOINT_GEN_H = DRIVE_PREFIX + \"/genh.pth.tar\"\n",
        "CHECKPOINT_GEN_S = DRIVE_PREFIX + \"/gens.pth.tar\"\n",
        "CHECKPOINT_CRITIC_H = DRIVE_PREFIX + \"/critich.pth.tar\"\n",
        "CHECKPOINT_CRITIC_S = DRIVE_PREFIX + \"/critics.pth.tar\"\n",
        "\n",
        "transforms_list = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    additional_targets={\"image0\": \"image\"},\n",
        ")"
      ],
      "id": "-Bfbt-m4GgxT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf9INbv5LZ5D"
      },
      "source": [
        "## Utils"
      ],
      "id": "Cf9INbv5LZ5D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-CiDKHLLa2b"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, filename):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename+'.pth.tar')\n",
        "    !cp {filename+'.pth.tar'} DRIVE_PREFIX\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ],
      "id": "G-CiDKHLLa2b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUhKIZioMb7f"
      },
      "source": [
        "## Load datasets"
      ],
      "id": "aUhKIZioMb7f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVFqc5lVDkBN",
        "outputId": "19bb4ee8-4f44-4b1b-8a59-1ba777310cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "NVFqc5lVDkBN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b11bc436-585b-45c0-8991-c4b3ffeeebe4"
      },
      "outputs": [],
      "source": [
        "# Train/test dataloader.\n",
        "class SimpsonsHumansDataset(Dataset):\n",
        "    def __init__(self, root_simpsons, root_human, transform=None):\n",
        "        super().__init__()\n",
        "        self.root_simpsons = root_simpsons\n",
        "        self.root_human = root_human\n",
        "        self.transform = transform\n",
        "\n",
        "        self.simpsons_images = os.listdir(root_simpsons)\n",
        "        self.human_images = os.listdir(root_human)\n",
        "        self.simpsons_len = len(self.simpsons_images)\n",
        "        self.humans_len = len(self.human_images)\n",
        "        self.length_dataset = max(self.simpsons_len, self.humans_len)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        simpsons_img = self.simpsons_images[index % self.simpsons_len]\n",
        "        human_img = self.human_images[index % self.humans_len]\n",
        "\n",
        "        simpsons_path = os.path.join(self.root_simpsons, simpsons_img)\n",
        "        humans_path = os.path.join(self.root_human, human_img)\n",
        "\n",
        "        simpsons_img = np.array(Image.open(simpsons_path).convert(\"RGB\"))\n",
        "        human_img = np.array(Image.open(humans_path).convert(\"RGB\"))\n",
        "\n",
        "        if self.transform:\n",
        "            augmentations = self.transform(image=simpsons_img, image0=human_img)\n",
        "            simpsons_img = augmentations[\"image\"]\n",
        "            human_img = augmentations[\"image0\"]\n",
        "\n",
        "        return simpsons_img, human_img"
      ],
      "id": "b11bc436-585b-45c0-8991-c4b3ffeeebe4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vlt03lL_MhTh"
      },
      "source": [
        "## Generator"
      ],
      "id": "Vlt03lL_MhTh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd31660c-d2f8-43ed-b502-c2ba6a313779"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n",
        "        if down\n",
        "        else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True) if use_act else nn.Identity()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    self.block = nn.Sequential(\n",
        "        ConvBlock(channels, channels, kernel_size=3, padding=1),\n",
        "        ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, img_channels, num_features=64, num_residuals=9):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                img_channels,\n",
        "                num_features,\n",
        "                kernel_size=7,\n",
        "                stride=1,\n",
        "                padding=3,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.InstanceNorm2d(num_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.down_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(\n",
        "                    num_features, num_features * 2, kernel_size=3, stride=2, padding=1\n",
        "                ),\n",
        "                ConvBlock(\n",
        "                    num_features * 2,\n",
        "                    num_features * 4,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            *[ResidualBlock(num_features * 4) for _ in range(num_residuals)]\n",
        "        )\n",
        "        self.up_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(\n",
        "                    num_features * 4,\n",
        "                    num_features * 2,\n",
        "                    down=False,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                    output_padding=1,\n",
        "                ),\n",
        "                ConvBlock(\n",
        "                    num_features * 2,\n",
        "                    num_features * 1,\n",
        "                    down=False,\n",
        "                    kernel_size=3,\n",
        "                    stride=2,\n",
        "                    padding=1,\n",
        "                    output_padding=1,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # To RGB\n",
        "        self.last = nn.Conv2d(\n",
        "            num_features * 1,\n",
        "            img_channels,\n",
        "            kernel_size=7,\n",
        "            stride=1,\n",
        "            padding=3,\n",
        "            padding_mode=\"reflect\",\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        for layer in self.down_blocks:\n",
        "            x = layer(x)\n",
        "        x = self.res_blocks(x)\n",
        "        for layer in self.up_blocks:\n",
        "            x = layer(x)\n",
        "        return torch.tanh(self.last(x))"
      ],
      "id": "dd31660c-d2f8-43ed-b502-c2ba6a313779"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU0qoOlLMkmt"
      },
      "source": [
        "## Discriminator"
      ],
      "id": "mU0qoOlLMkmt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RwWY7hErP7J"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=True, padding_mode=\"reflect\"),\n",
        "        nn.InstanceNorm2d(out_channels), # normalizes each sample, not entire batch\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
        "    super().__init__()\n",
        "    self.initial = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, features[0], kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "    layers=[]\n",
        "    in_channels = features[0]\n",
        "    for feature in features[1:]:\n",
        "      layers.append(Block(in_channels, feature, stride=1 if features[-1] else 2)) # join (downsize conv2d blocks) until last block\n",
        "      in_channels = feature\n",
        "    layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode='reflect')) # add final conv2d\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.initial(x)\n",
        "    return torch.sigmoid(self.model(x))"
      ],
      "id": "6RwWY7hErP7J"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JwdmLuMMoxh"
      },
      "source": [
        "## Training"
      ],
      "id": "1JwdmLuMMoxh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMdJbTHVSC73"
      },
      "outputs": [],
      "source": [
        "def train_fn(\n",
        "    disc_H, disc_S, gen_S, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler\n",
        "):\n",
        "    H_reals = 0\n",
        "    H_fakes = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    avg_loss_D, avg_loss_G = None, None\n",
        "\n",
        "    for idx, (simpsons, human) in enumerate(loop):\n",
        "        simpsons = simpsons.to(device)\n",
        "        human = human.to(device)\n",
        "\n",
        "        # Train Discriminators H and S\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_human = gen_H(simpsons)\n",
        "            D_H_real = disc_H(human)\n",
        "            D_H_fake = disc_H(fake_human.detach())\n",
        "            H_reals += D_H_real.mean().item()\n",
        "            H_fakes += D_H_fake.mean().item()\n",
        "            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n",
        "            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n",
        "            D_H_loss = D_H_real_loss + D_H_fake_loss\n",
        "\n",
        "            fake_simpsons = gen_S(human)\n",
        "            D_S_real = disc_S(simpsons)\n",
        "            D_S_fake = disc_S(fake_simpsons.detach())\n",
        "            D_S_real_loss = mse(D_S_real, torch.ones_like(D_S_real))\n",
        "            D_S_fake_loss = mse(D_S_fake, torch.zeros_like(D_S_fake))\n",
        "            D_S_loss = D_S_real_loss + D_S_fake_loss\n",
        "\n",
        "            # put it togethor\n",
        "            D_loss = (D_H_loss + D_S_loss) / 2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train Generators H and S\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial loss for both generators\n",
        "            D_H_fake = disc_H(fake_human)\n",
        "            D_S_fake = disc_S(fake_simpsons)\n",
        "            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n",
        "            loss_G_S = mse(D_S_fake, torch.ones_like(D_S_fake))\n",
        "\n",
        "            # cycle loss\n",
        "            cycle_simpsons = gen_S(fake_human)\n",
        "            cycle_human = gen_H(fake_simpsons)\n",
        "            cycle_simpsons_loss = l1(simpsons, cycle_simpsons)\n",
        "            cycle_human_loss = l1(human, cycle_human)\n",
        "\n",
        "            # add all togethor\n",
        "            G_loss = (\n",
        "                loss_G_S\n",
        "                + loss_G_H\n",
        "                + cycle_simpsons_loss * LAMBDA_CYCLE\n",
        "                + cycle_human_loss * LAMBDA_CYCLE\n",
        "            )\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        # Keep track of loss over time\n",
        "        if avg_loss_D is None:\n",
        "          avg_loss_D = D_loss\n",
        "        else:\n",
        "          avg_loss_D = avg_loss_D + ((1 / idx + 1)) * (D_loss - avg_loss_D)\n",
        "        if avg_loss_G is None:\n",
        "          avg_loss_G = G_loss\n",
        "        else:\n",
        "          avg_loss_G = avg_loss_G + ((1 / idx + 1)) * (G_loss - avg_loss_G)\n",
        "\n",
        "        # Save images as we go, except for every image in the last epoch\n",
        "        if idx % 200 == 0 or epoch == NUM_EPOCHS - 1:\n",
        "            save_image(fake_human * 0.5 + 0.5, DRIVE_PREFIX + f\"/mid/human{epoch}_{idx}_{RUN_NUM}.png\")\n",
        "            save_image(fake_simpsons * 0.5 + 0.5, DRIVE_PREFIX + f\"/mid/simpsons{epoch}_{idx}_{RUN_NUM}.png\")\n",
        "\n",
        "        loop.set_postfix(H_real=H_reals / (idx + 1), H_fake=H_fakes / (idx + 1))\n",
        "\n",
        "        del simpsons, human, \n",
        "        fake_human, D_H_loss, D_H_real_loss, D_H_fake_loss,\n",
        "        fake_simpsons, D_S_loss, D_S_real_loss, D_S_fake_loss,\n",
        "        D_loss,\n",
        "        D_H_fake, D_S_fake, loss_G_H, loss_G_S,\n",
        "        cycle_simpsons, cycle_human, cycle_simpsons_loss, cycle_human_loss,\n",
        "        G_loss\n",
        "        # free up GPU memory\n",
        "    loss_D_f = open(DRIVE_PREFIX + '/loss/training_loss_D.txt', 'a')\n",
        "    loss_G_f = open(DRIVE_PREFIX + '/loss/training_loss_G`.txt', 'a')\n",
        "    loss_D_f.write(f'{avg_loss_D}\\n')\n",
        "    loss_G_f.write(f'{avg_loss_G}\\n')\n",
        "    loss_D_f.close()\n",
        "    loss_G_f.close()"
      ],
      "id": "dMdJbTHVSC73"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqKlhR2ZJ7kY"
      },
      "source": [
        "## Testing"
      ],
      "id": "MqKlhR2ZJ7kY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5yHiAQ3J6oK"
      },
      "outputs": [],
      "source": [
        "# Basically the same as the training code, except we don't update the model.\n",
        "# Choose one random image to test loss for each epoch, and one consistent image to save to track progress\n",
        "# If \"final\" is set to True, then evaluate and save all images\n",
        "def test_fn(\n",
        "    disc_H, disc_S, gen_S, gen_H, loader, opt_disc, l1, mse, final=False\n",
        "):\n",
        "    rand_idx = randrange(100)\n",
        "    H_reals = 0\n",
        "    H_fakes = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    loss_D_f = open(DRIVE_PREFIX + '/loss/test_loss_D.txt', 'a')\n",
        "    loss_G_f = open(DRIVE_PREFIX + '/loss/test_loss_G.txt', 'a')\n",
        "\n",
        "    for idx, (simpsons, human) in enumerate(loop):\n",
        "        if not final and idx != rand_idx and idx != 0:\n",
        "          continue\n",
        "        simpsons = simpsons.to(device)\n",
        "        human = human.to(device)\n",
        "\n",
        "        # Train Discriminators H and S\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_human = gen_H(simpsons)\n",
        "            D_H_real = disc_H(human)\n",
        "            D_H_fake = disc_H(fake_human.detach())\n",
        "            H_reals += D_H_real.mean().item()\n",
        "            H_fakes += D_H_fake.mean().item()\n",
        "            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n",
        "            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n",
        "            D_H_loss = D_H_real_loss + D_H_fake_loss\n",
        "\n",
        "            fake_simpsons = gen_S(human)\n",
        "            D_S_real = disc_S(simpsons)\n",
        "            D_S_fake = disc_S(fake_simpsons.detach())\n",
        "            D_S_real_loss = mse(D_S_real, torch.ones_like(D_S_real))\n",
        "            D_S_fake_loss = mse(D_S_fake, torch.zeros_like(D_S_fake))\n",
        "            D_S_loss = D_S_real_loss + D_S_fake_loss\n",
        "\n",
        "            # put it togethor\n",
        "            D_loss = (D_H_loss + D_S_loss) / 2\n",
        "\n",
        "        # Train Generators H and S\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial loss for both generators\n",
        "            D_H_fake = disc_H(fake_human)\n",
        "            D_S_fake = disc_S(fake_simpsons)\n",
        "            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n",
        "            loss_G_S = mse(D_S_fake, torch.ones_like(D_S_fake))\n",
        "\n",
        "            # cycle loss\n",
        "            cycle_simpsons = gen_S(fake_human)\n",
        "            cycle_human = gen_H(fake_simpsons)\n",
        "            cycle_simpsons_loss = l1(simpsons, cycle_simpsons)\n",
        "            cycle_human_loss = l1(human, cycle_human)\n",
        "\n",
        "            # add all togethor\n",
        "            G_loss = (\n",
        "                loss_G_S\n",
        "                + loss_G_H\n",
        "                + cycle_simpsons_loss * LAMBDA_CYCLE\n",
        "                + cycle_human_loss * LAMBDA_CYCLE\n",
        "            )\n",
        "\n",
        "        # Keep track of loss over time\n",
        "        if not final and idx == rand_idx:\n",
        "            loss_D_f.write(f'{D_loss}\\n')\n",
        "            loss_G_f.write(f'{G_loss}\\n')\n",
        "\n",
        "        # Save first image at every epoch\n",
        "        if not final and idx == 0:\n",
        "          save_image(fake_human * 0.5 + 0.5, DRIVE_PREFIX + f\"/tests/human{epoch}_{idx}_{RUN_NUM}.png\")\n",
        "          save_image(fake_simpsons * 0.5 + 0.5, DRIVE_PREFIX + f\"/tests/simpsons{epoch}_{idx}_{RUN_NUM}.png\")\n",
        "\n",
        "        if final:\n",
        "          save_image(fake_human * 0.5 + 0.5, DRIVE_PREFIX + f\"/final_output/human_{idx}.png\")\n",
        "          save_image(fake_simpsons * 0.5 + 0.5, DRIVE_PREFIX + f\"/final_output/simpsons_{idx}.png\")\n",
        "\n",
        "        loop.set_postfix(H_real=H_reals / (idx + 1), H_fake=H_fakes / (idx + 1))\n",
        "\n",
        "        del simpsons, human, \n",
        "        fake_human, D_H_loss, D_H_real_loss, D_H_fake_loss,\n",
        "        fake_simpsons, D_S_loss, D_S_real_loss, D_S_fake_loss,\n",
        "        D_loss,\n",
        "        D_H_fake, D_S_fake, loss_G_H, loss_G_S,\n",
        "        cycle_simpsons, cycle_human, cycle_simpsons_loss, cycle_human_loss,\n",
        "        G_loss\n",
        "        # free up GPU memory\n",
        "    loss_D_f.close()\n",
        "    loss_G_f.close()"
      ],
      "id": "A5yHiAQ3J6oK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdBbyMq8FhUH"
      },
      "source": [
        "## Run Training"
      ],
      "id": "tdBbyMq8FhUH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqo2qCDuFglB",
        "outputId": "a1ce3626-9369-41cf-de18-8372a6f7055d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Loading checkpoint\n",
            "=> Loading checkpoint\n",
            "=> Loading checkpoint\n",
            "=> Loading checkpoint\n"
          ]
        }
      ],
      "source": [
        "disc_H = Discriminator(in_channels=3).to(device)\n",
        "disc_S = Discriminator(in_channels=3).to(device)\n",
        "gen_S = Generator(img_channels=3, num_residuals=9).to(device)\n",
        "gen_H = Generator(img_channels=3, num_residuals=9).to(device)\n",
        "opt_disc = optim.Adam(\n",
        "    list(disc_H.parameters()) + list(disc_S.parameters()),\n",
        "    lr=LEARNING_RATE,\n",
        "    betas=(0.5, 0.999),\n",
        ")\n",
        "\n",
        "opt_gen = optim.Adam(\n",
        "    list(gen_S.parameters()) + list(gen_H.parameters()),\n",
        "    lr=LEARNING_RATE,\n",
        "    betas=(0.5, 0.999),\n",
        ")\n",
        "\n",
        "L1 = nn.L1Loss()\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "if LOAD_MODEL:\n",
        "    load_checkpoint(\n",
        "        DRIVE_PREFIX+'/CHECKPOINT_GEN_H.pth.tar',\n",
        "        gen_H,\n",
        "        opt_gen,\n",
        "        LEARNING_RATE,\n",
        "    )\n",
        "    load_checkpoint(\n",
        "        DRIVE_PREFIX+'/CHECKPOINT_GEN_S.pth.tar',\n",
        "        gen_S,\n",
        "        opt_gen,\n",
        "        LEARNING_RATE,\n",
        "    )\n",
        "    load_checkpoint(\n",
        "        DRIVE_PREFIX+'/CHECKPOINT_CRITIC_H.pth.tar',\n",
        "        disc_H,\n",
        "        opt_disc,\n",
        "        LEARNING_RATE,\n",
        "    )\n",
        "    load_checkpoint(\n",
        "        DRIVE_PREFIX+'/CHECKPOINT_CRITIC_S.pth.tar',\n",
        "        disc_S,\n",
        "        opt_disc,\n",
        "        LEARNING_RATE,\n",
        "    )\n",
        "\n",
        "dataset = SimpsonsHumansDataset(\n",
        "    root_human=TRAIN_DIR + \"/humans\",\n",
        "    root_simpsons=TRAIN_DIR + \"/simpsons\",\n",
        "    transform=transforms_list,\n",
        ")\n",
        "val_dataset = SimpsonsHumansDataset(\n",
        "    root_human=VAL_DIR + \"/humans\",\n",
        "    root_simpsons=VAL_DIR + \"/simpsons\",\n",
        "    transform=transforms_list,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        ")\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        ")\n",
        "g_scaler = torch.cuda.amp.GradScaler()\n",
        "d_scaler = torch.cuda.amp.GradScaler()\n"
      ],
      "id": "cqo2qCDuFglB"
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"Epoch {epoch}/{NUM_EPOCHS-1}\")\n",
        "    train_fn(\n",
        "        disc_H,\n",
        "        disc_S,\n",
        "        gen_S,\n",
        "        gen_H,\n",
        "        loader,\n",
        "        opt_disc,\n",
        "        opt_gen,\n",
        "        L1,\n",
        "        mse,\n",
        "        d_scaler,\n",
        "        g_scaler\n",
        "    )\n",
        "\n",
        "    if SAVE_MODEL:\n",
        "        save_checkpoint(gen_H, opt_gen, filename='CHECKPOINT_GEN_H')\n",
        "        save_checkpoint(gen_S, opt_gen, filename='CHECKPOINT_GEN_S')\n",
        "        save_checkpoint(disc_H, opt_disc, filename='CHECKPOINT_CRITIC_H')\n",
        "        save_checkpoint(disc_S, opt_disc, filename='CHECKPOINT_CRITIC_S')\n",
        "\n",
        "    test_fn(\n",
        "        disc_H,\n",
        "        disc_S,\n",
        "        gen_S,\n",
        "        gen_H,\n",
        "        val_loader,\n",
        "        opt_disc,\n",
        "        L1,\n",
        "        mse\n",
        "    )"
      ],
      "metadata": {
        "id": "jzpUjL0jtU-z"
      },
      "id": "jzpUjL0jtU-z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate final images"
      ],
      "metadata": {
        "id": "tWnCRXbSQz1o"
      },
      "id": "tWnCRXbSQz1o"
    },
    {
      "cell_type": "code",
      "source": [
        "test_fn(\n",
        "      disc_H,\n",
        "      disc_S,\n",
        "      gen_S,\n",
        "      gen_H,\n",
        "      val_loader,\n",
        "      opt_disc,\n",
        "      L1,\n",
        "      mse,\n",
        "      final=True\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB2OUrQmQ44O",
        "outputId": "719bc3fd-b985-4d16-fb5f-ceee1ce8e5e2"
      },
      "id": "mB2OUrQmQ44O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:52<00:00,  1.13s/it, H_fake=0.393, H_real=0.634]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "nMKFHB5UMO9_",
        "Cf9INbv5LZ5D",
        "aUhKIZioMb7f",
        "Vlt03lL_MhTh",
        "mU0qoOlLMkmt",
        "1JwdmLuMMoxh",
        "tdBbyMq8FhUH"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}